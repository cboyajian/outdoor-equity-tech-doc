# User Documentation

## Purpose of the Outdoor Equity App

The [Outdoor Equity App](https://shinyapps.bren.ucsb.edu/oe_app/) provides users with tools to explore trends at different overnight reservable sites to analyze access to these sites. The intended audience is federal public land managers and researchers as well as nonprofit organizations and recreation users. 

The [Recreation Information Database (RIDB) data](https://ridb.recreation.gov/landing) are comprehensive when it comes to information regarding the site and reservation, but do not include information about the visitor outside of their home ZIP code. [US Census American Community Survey (ACS) data](https://www.census.gov/programs-surveys/acs/data.html) is used to approximate socioeconomic demographics by joining information about the visitors’ home ZIP code to the RIDB data. 


## How to Use the Outdoor Equity App

### About the App

The About tab of the [Outdoor Equity App](https://shinyapps.bren.ucsb.edu/oe_app/) includes background information about what the App is, why outdoor recreation is important, the App creators, and what data is used in the App. These sections are similar to the [About Section][About] of this technical documentation. The About tab also includes example questions that a user might explore through the different parts of the Analysis tab. 

The Analysis tab of the App consists of three parts Data Summary, Data Relationship and Visitorshed Maps. Each of these pages includes a brief explanatory section of how to interpret the plot or graph, a section to subset the data to the desired campsite, and the plot or map outputs.

The Metadata tab of the App includes metadata for all variables in the combined RIDB and ACS dataset. This section mirrors the Metadata section in the [Products and Deliverables Section][Products and Deliverables] of this document. 

The Data Download section of the App allows a user to download a subset of data include as many or as few campsites and variables as they require for further analysis or use.


## How to Maintain the Outdoor Equity App

### Data Preparation Methods

#### RIDB Data

[RIDB data](https://ridb.recreation.gov/landing) data are available through direct download as CSV files or via the API as JSON files via Recreation.gov. API access requires creating a Recreation.gov account and requesting second tier API access via the Recreation.gov website’s Contact Us page. CSV files are readily available for download via the [Recreation.gov website](https://ridb.recreation.gov/download). Data are collected each time a visitor makes a reservation through Recreation.gov. Data packages are posted annually in the spring by R1S and contain the previous fiscal year’s reservations (ex: the 2018 package includes 2018-10-01 through 2018-09-30). Data packages are available for download from 2006 to present. Each annual data package file contains a range between 2 million and 5 million observations (or reservations) and includes variables in character, numeric, and date/time formats about each reservation. A shift in the data collection and storage processes occurred in 2019, changing what variables are available and how they are labeled. Currently, the Outdoor Equity App contains only data for reservable sites in California and reservations for fiscal year 2018. 

A reproducible workflow for cleaning and wrangling data is employed in the `data_wrangle_and_clean.Rmd` document that sources custom functions to prepare RIDB data for joining with ACS data. All custom functions locations within the repository are listed in the [Access, Clean, and Wrangle Data Section][Access, Clean, and Wrangle Data] of this document. These functions rely heavily on functions from the `tidyverse` collection of packages [@R-tidyverse].

```{r, include=FALSE}
ridb_data_ca_overnight_only <- ridb_data %>% 
  janitor::clean_names() %>% 
  filter(facility_state == "CA") %>% 
  filter(use_type == "Overnight")
```

First, a the `function_ridb_subset-pre2018.R` is used to subset the RIDB data, filtering only reservations within the selected state that are listed as “Overnight” reservations within the `use_type` variable. For the 2018 California dataset this results in a starting "raw" data frame with `r comma(nrow(ridb_data_ca_overnight_only))` reservations 

```{r, eval=FALSE}
# filter for state
filter(facility_state == state_abbrev) %>%
  # filter for use type
  filter(use_type == "Overnight")
```

The function then selects only the necessary variables, including information about the site (agency, park or forest name, site name, site type, and site location) and information about the reservation (home ZIP come, total paid, visit start and end dates, visit order date, and number of people in party).

```{r, eval=FALSE}
# select variables
select(c("agency", "parent_location", "region_description", 
         "park", "site_type", "facility_id", "facility_state", 
         "facility_longitude", "facility_latitude", 
         "customer_zip", "total_paid", "start_date",
         "end_date", "order_date", "number_of_people")) %>%
  mutate(site_type = tolower(site_type)) %>%
  filter(!site_type %in% c("historic tour", "hiking zone", 
                           "group picnic area", "cave tour",
                           "management", "picnic", 
                           "entry point", "trailhead"))
```

The customer ZIP code values are then normalized. This includes filtering for only US ZIP codes and shortening all 9 digit ZIP codes to include only the first 5 digits.

```{r, eval=FALSE}
# filter out invalid ZIP codes
filter(str_detect(string = customer_zip,
                  pattern = "^[:digit:]{5}(?!.)") |
         str_detect(string = customer_zip,
                    pattern = "^[:digit:]{5}(?=-)")) %>%
  filter(!customer_zip %in% c("00000", "99999")) %>%
  mutate(customer_zip = str_extract(string = customer_zip,
                                    pattern = "[:digit:]{5}"))
```


This function results in the removal of `r comma(nrow(ridb_data_ca_overnight_only) - nrow(data_joined_2018))` reservations (or `r percent((nrow(ridb_data_ca_overnight_only) - nrow(data_joined_2018)) / nrow(ridb_data_ca_overnight_only), accuracy = 0.01)`) from the original "raw" dataset that included all reservations for reservable overnight campsites in California. 

```{r, include=FALSE}
no_valid_booking_window <- data_joined_2018 %>% 
  mutate(booking_window = as.numeric(difftime(start_date, order_date),
                                     units = "days")) %>% 
  filter(booking_window < 0)
```

A second custom function is then utilized to calculate and manipulate variables of interest. Start, end, and order dates calculate the lengths of stay and booking windows (number of days from order to start date) of each reservation. The booking window calculations return a number of results that are negative. This is a known issue that others working with the RIDB data have encountered. This resulted in `r comma(nrow(no_valid_booking_window))` reservations (or `r percent(nrow(no_valid_booking_window) / nrow(ridb_data_ca_overnight_only), accuracy = 0.01)`) without a valid booking window. 

```{r, eval=FALSE}
mutate(start_date = as.Date(start_date),
       end_date = as.Date(end_date),
       order_date = as.Date(order_date),
       # calculate new variables
       length_of_stay = as.numeric(difftime(end_date, start_date), 
                                   units = "days"),
       booking_window = as.numeric(difftime(start_date, order_date), 
                                   units = "days"))
```

Total costs are divided by lengths of stay to calculate cost per day and cost per day per visitor. 

```{r, eval=FALSE}
# calculate new variables
mutate(daily_cost = total_paid / length_of_stay,
       daily_cost_per_visitor = daily_cost / number_of_people)
```

Site types are aggregated to create 7 broader site categories.

```{r, eval=FALSE}
# aggregate site type
mutate(aggregated_site_type = 
         case_when(site_type %in% c("walk to", "hike to", 
                                    "group hike to", "group walk to"
         ) ~ "remote",
         site_type %in% c("cabin nonelectric", "cabin electric", 
                          "yurt","shelter nonelectric"
         ) ~ "shelter",
         site_type %in% c("boat in", "anchorage") ~ "water",
         site_type %in% c("group equestrian", 
                          "equestrian nonelectric"
         ) ~ "equestrian",
         site_type %in% c("rv nonelectric", "rv electric", 
                          "group rv area nonelectric"
         ) ~ "rv only",
         site_type %in% c("group standard nonelectric", 
                          "standard nonelectric",
                          "standard electric", 
                          "group standard area nonelectric",
                          "group standard electric"
         ) ~ "rv or tent",
         site_type %in% c("tent only nonelectric", 
                          "group tent only area nonelectric",
                          "tent only electric"
         ) ~ "tent only"))
```

The administrative unit variable is created by combining the `parent_location` and `region_description` variables as different federal agencies track the administrative unit information in different variables. Then the `agency`, `admin_uni` and `park` variables character strings are updated using multiple functions from the `stringr` package [@R-stringr].

```{r, eval=FALSE}
mutate(admin_unit = 
         case_when(agency == "USFS" ~ parent_location,
                   agency %in% c(
                     "NPS", "BOR", "USACE"
                   ) ~ region_description)) %>% 
  # edit values
  mutate(
    # agency abbreviations to names
    agency = str_replace(string = agency,
                         pattern = "NPS",
                         replacement = "National Park Service"),
    agency = str_replace(string = agency,
                         pattern = "USFS", 
                         replacement = "US Forest Service"),
    agency = str_replace(string = agency,
                         pattern = "USACE",
                         replacement = "US Army Corps of Engineers"),
    agency = str_replace(string = agency,
                         pattern = "BOR",
                         replacement = "Bureau of Reclamation"),
    # update admin_unit values (generic)
    admin_unit = str_replace(string = admin_unit,
                             pattern = paste(c("NF - FS", "NF -FS", 
                                               "NF- FS", "NF-FS", 
                                               "-FS", " - FS"), 
                                             collapse = "|"),
                             replacement = "National Forest"),
    admin_unit = str_to_title(admin_unit),
    admin_unit = str_replace(string = admin_unit,
                             pattern = "And",
                             replacement = "&"),
    # update park values (generic)
    park = str_remove(string = park,
                      pattern = paste(c("\\(.*", " \\(.*",
                                        "---.*", " ---.*",
                                        ",.*"), 
                                      collapse = "|")),
    park = str_to_title(park),
    park = str_replace(string = park,
                       pattern = "Cg",
                       replacement = "Campground"),
    park = str_replace(string = park,
                       pattern = "Nhp",
                       replacement = "National Historic Park"),
    park = str_replace(string = park,
                       pattern = "@",
                       replacement = "At"),
    park = str_replace(string = park,
                       pattern = "&",
                       replacement = "And"),
    park = str_replace(string = park,
                       pattern = paste(c("/", " / "), collapse = "|"),
                       replacement = " "),
    park = str_remove_all(string = park,
                          pattern = " \\d.*"),
    # update park values (CA specific)
    park = str_remove(string = park,
                      pattern = paste(c(" - Angeles Nf", " -Hwy"), 
                                      collapse = "|")),
    park = str_replace(string = park,
                       pattern = "Tunnel Mills Il",
                       replacement = "Tunnel Mills"))
```

Distance traveled is calculated by measuring the distance from the latitude and longitude facility coordinate locations to the centroid of the home ZIP code, which is accessed via the `tidycensus` package [@R-tidycensus].

```{r, eval=FALSE}
# bootstrap geometries and reproject to NAD 83
df_geometries <- df %>% 
  st_as_sf(coords = c("facility_longitude", "facility_latitude"),
           crs = 4326) %>% 
  st_transform(crs = 4269) # using NAD83 because measured in meters

# get centroid of geometries for all US ZIP codes 
df_zip_centroids_us <- 
  get_acs(geography = "zcta", year = 2018, 
          geometry = TRUE, 
          summary_var = "B01001_001",
          survey = "acs5",
          variables = c(male = "B01001_002")) %>% 
  select(NAME, geometry) %>% 
  mutate(zip_code = str_sub(NAME, start = -5, end = -1)) %>% 
  select(zip_code, geometry) %>% 
  st_centroid()

# join data and calculate `distance_traveled` variable
df_joined_geometries <- 
  left_join(x = df_geometries %>% as.data.frame(),
            y = df_zip_centroids_us %>% as.data.frame(), 
            by = c("customer_zip" = "zip_code")) %>%
  st_sf(sf_column_name = 'geometry.x') %>% 
  mutate(distance_traveled_m = st_distance(x = geometry.x, 
                                           y = geometry.y,
                                           by_element = TRUE),
         distance_traveled_m = as.numeric(distance_traveled_m)) 
```

And finally, a variable is added indicating in which state or territory each customer zip code is located. This portion of the code utilizes the `zipcodeR` package [@R-zipcodeR]. 

```{r, eval=FALSE}
# create df of fips and full state names
fips_list <- c(
  "01", "02", "04", "05", "06", "08", "09", "10", "11", "12", 
  "13", "15", "16", "17", "18", "19", "20", "21", "22", "23", 
  "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", 
  "34", "35", "36", "37", "38", "39", "40", "41", "42", "44", 
  "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", 
  "56", "72")
state_list <- c(
  "AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL",
  "GA", "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME",
  "MD", "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH",
  "NJ", "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI",
  "SC", "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI",
  "WY", "PR")
states_names_list <- c(
  "Alabama", "Alaska", "Arizona", "Arkansas", "California", 
  "Colorado", "Connecticut", "Delaware", 
  "District of Columbia", "Florida","Georgia", "Hawaii", 
  "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", 
  "Kentucky", "Louisiana", "Maine","Maryland", 
  "Massachusetts", "Michigan", "Minnesota", "Mississippi", 
  "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire",
  "New Jersey", "New Mexico", "New York", "North Carolina", 
  "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", 
  "Rhode Island","South Carolina", "South Dakota", "Tennessee", 
  "Texas", "Utah", "Vermont", "Virginia", "Washington", 
  "West Virginia", "Wisconsin","Wyoming", "Puerto Rico")
df_states_fips <- as.data.frame(list(fips = fips_list,
                                     state = state_list,
                                     state_full = states_names_list))

# loop through state df to get all ZIP codes w/in state
df_states_zip_codes <- data.frame()

for (i in seq_along(fips_list)){
  state <- zipcodeR::search_fips(state_fips = fips_list[[i]]) %>% 
    select(zipcode, state)
  df_states_zip_codes <- rbind(df_states_zip_codes, state)
}

# add full state name and fips code to list of all ZIP codes for each state
df_states_fips_zip_codes <- 
  left_join(x = df_states_zip_codes,
            y = df_states_fips,
            by = "state") %>% 
  select(-fips) %>% 
  rename(customer_zip_state = state,
         customer_zip_state_full = state_full,
         zip_code = zipcode)
```


#### U.S. Census Data

US Census data is publicly accessible in many ways. Our product utilizes the R package `tidycensus` [@R-tidycensus] to access the necessary variables from the 2018 [American Community Survey (ACS)](https://www.census.gov/programs-surveys/acs/data.html) via API. API access requires an api key, which can be . 

```{r, eval=FALSE, message=FALSE}
# API set up
# ONLY HAVE TO RUN THE FIRST TIME USING THIS RMD on a new machine
census_api <- source("private/census-api.R")
census_api_key(key = census_api[[1]], install = TRUE, overwrite = TRUE)
# run in console:
readRenviron("~/.Renviron")

# look at option variables
#View(load_variables(2018, "acs5", cache = TRUE))
```

Sample data are collected for the ACS each year and includes many variables that cover social, economic, housing, and demographic characteristics. The Outdoor Equity App utilizes the [ACS 5-year data](https://www.census.gov/data/developers/data-sets/acs-5year.html), which is an estimate representing data collected over the designated 5 year period. We used the 5-year ACS data over the 1-year ACS data because it increases "statistical reliability of the data for less populated areas and small population subgroups" [@ACS].

The variables included in the App include median-income, race, language(s) spoken at home, and highest level of education attained. All variables are represented as estimates in numeric format for a ZIP code tabulation area. Data are called by geographic region, in our case the ZIP code tabulation area, and include an estimated number of people that fall into each category within each ZIP code, a margin of error, and an estimated number of total people in the area. Within our custom functions `function_acs_education.R`, `function_acs_language.R`, `function_acs_median_income.R`, and `function_acs_race.R` we first imported just the necessary columns for each ACS variable. 

```{r}
# import variables for race
race_df <- 
  get_acs(
    geography = "zcta", year = 2018,
    state = "CA",
    summary_var = "B03002_001", #Estimate!!Total: 
    variables = c(
      white = "B03002_003", #White alone
      black = "B03002_004", #Black or African American alone
      native_american = "B03002_005", #American Indian and Alaska Native alone
      asian = "B03002_006", #Asian alone
      pacific_islander = "B03002_007", #Native Hawaiian and Other Pacific Islander alone
      other = "B03002_008", #Some other race alone
      multiracial = "B03002_009", #Two or more races
      hispanic_latinx = "B03002_012" #Hispanic or Latino
    ))
```


```{r, message=FALSE, echo=FALSE}
knitr::kable(head(race_df, 10),
             caption = "Example of raw ACS Race Variable.")
```

Percentages for the categories within each ACS variable are calculated for race, language(s) spoken in the home, and highest level of education by dividing the estimate for a category by the estimated total population for that ZIP code. 

```{r, eval=FALSE}
df_percent <- 
  race_df %>% 
  group_by(zip_code, race) %>% 
  summarise(estimate = sum(estimate),
            moe = sum(moe),
            summary_est = unique(summary_est),
            summary_moe = unique(summary_moe),
            percent = estimate / summary_est)
```

For median-income, the estimated median-income is used as is, without further adjustments. 

```{r, eval=FALSE}
df <- 
  get_acs(geography = "zcta", year = 2018,
          state = "CA",
          variables = c(
            median_income = "B19013_001" 
          )) %>% 
  clean_names() %>% 
  rename(median_income = estimate) %>% 
  mutate(zip_code = str_sub(name, start = -5, end = -1)) %>% 
  select(median_income, zip_code)
```

ACS data are then pivoted wider, moving the different categories and percentages (ex: racial groups) to their own columns to create a single row for each ZIP code. This is necessary for joining the ACS data sets to the RIDS data set. 

```{r, eval=FALSE}
select(zip_code, summary_est, race, percent) %>% 
  rename(zip_code_population = summary_est) %>% 
  # create column for each percentage for each group (pivot_wider)
  # necessary to be able to left_join() with RIDB data
  pivot_wider(names_from = "race",
              values_from = "percent")
```



### Statistical Analysis and Data Wrangling for Plots

Each type of plot and map require unique data wrangling which is explained in this section.

#### Data Summary

We created custom functions for data wrangling and plotting for use within the R Shiny App code. Wrangling begins with filtering based on the user’s choice campsite input. We then further subset the dataset to include only the necessary columns for plotting. Histograms or bar charts show the distribution of the data for each variable. For ACS plots, data from reservations are plotted against data for the full California population in order to show where reservations either under- or over-represent that variable. 

```{r, eval=FALSE}
# example for booking window data summary
booking_window_rdf <- reactive({
  validate(
    need(siteInput != "",
         "Please select a reservable site to visualize.")
  ) # EO validate
  
  ridb_df %>%
    filter(park %in% siteInput,
           booking_window > 0,
           booking_window != "Inf") %>% 
    select(park, booking_window) %>% 
    filter(!is.na(booking_window))
})
```


#### Data Relationships

Visualizing the relationship between RIDB and ACS variables is challenging because the socioeconomic data available are an estimate of the ZIP code population, rather than data of the individual making the reservation. In order to create simple, easy to interpret plots, we determined whether reservations were from a location with “high” percentages of a given ACS variable category (ex: one of the eight racial groups). We determined “high” as above the weighted 3rd quartile based on census data for all of California. This method allows for reservations to be included in the “high” category for multiple values within one ACS variable. By allowing a reservation to appear in multiple categories within a single ACS variable, the uncertainty of the reserver’s actual socioeconomic status is retained. 

```{r, include=FALSE}
source("r/function_acs_education.R")
source("r/function_acs_language.R")
source("r/function_acs_race.R")
source("r/function_acs_median_income.R")

# read in census data for CA
acs_subset_calculate_race(geography = "zcta", year = 2018, state = "California")
acs_subset_calculate_education(geography = "zcta", year = 2018, state = "California")
acs_subset_calculate_language(geography = "zcta", state = "California")
acs_subset_calculate_median_income(geography = "zcta", year = 2018, state = "California")

# combine all CA census variables
acs_ca_all <- left_join(x = data_acs_2018_education_percent_California,
                     y = data_acs_2018_median_income_California,
                     by = "zip_code") %>% 
  left_join(y = data_acs_2018_race_percent_California,
            by = "zip_code") %>% 
  left_join(y = data_acs_2020_language_percent_California,
            by = "zip_code")

data_acs_ca_all <- acs_ca_all %>% 
  mutate(mean_zip_code_population = rowMeans(acs_ca_all[,c(2,8,17)])) %>% 
  select(-c("zip_code_population.x", 
            "zip_code_population.y",
            "zip_code_population"))
```


```{r, include=FALSE}
source("r/function_acs_top_quartile_language.R")

# language groups
language_group <- c("english_only", "not_english_only")

# calculate value of 3rd quartile for each language group
language_quants_df <-
  language_group %>%
  map_dbl(language_top_quartile, acs_df = data_acs_ca_all) %>%
  cbind("language_group" = language_group,
        "weighted_quartile" = .) %>%
  as.data.frame() %>% 
  mutate(language_group = str_replace_all(string = language_group,
                                          pattern = "_",
                                          replacement = " "),
         language_group = str_to_title(language_group),
         weighted_quartile = percent(as.numeric(weighted_quartile), accuracy = 0.01)) %>% 
  rename("Language Group" = language_group,
         "Threshold" = weighted_quartile)
```

```{r, include=FALSE}
source("r/function_acs_top_quartile_education.R")

# education groups
education_group <-
  c("hs_GED_or_below", "some_college",  "college", "master_or_above")

# calculate value of 3rd quartile for each educational group
education_quants_df <-
  education_group %>%
  map_dbl(education_top_quartile, acs_df = data_acs_ca_all) %>%
  cbind("education_group" = education_group,
        "weighted_quartile" = .) %>%
  as.data.frame() %>% 
  mutate(education_group = str_replace_all(string = education_group,
                                           pattern = "_",
                                           replacement = " "),
         education_group = str_to_title(education_group),
         weighted_quartile = percent(as.numeric(weighted_quartile), accuracy = 0.01)) %>% 
  rename("Education Group" = education_group,
         "Threshold" = weighted_quartile)
```

```{r, include=FALSE}
source("r/function_acs_top_quartile_race.R")

# race groups
race_group <- c(
  "other", "pacific_islander",  "multiracial",  "asian",
  "black",  "white", "native_american", "hispanic_latinx")

# calculate value of 3rd quartile for each racial group
race_quants_df <-
  race_group %>%
  map_dbl(race_top_quartile, acs_df = data_acs_ca_all) %>%
  cbind("race_group" = race_group,
        "weighted_quartile" = .) %>%
  as.data.frame() %>% 
  mutate(race_group = str_replace_all(string = race_group,
                                      pattern = "_",
                                      replacement = " "),
         race_group = str_to_title(race_group),
         weighted_quartile = percent(as.numeric(weighted_quartile), accuracy = 0.01)) %>% 
  rename("Race Group" = race_group,
         "Threshold" = weighted_quartile)
```

```{r, echo=FALSE}
knitr::kable(list(language_quants_df, education_quants_df,
                  race_quants_df), 
             caption = "Threshold values for ACS variables.")
```



#### Spatial analysis




### Data updates

The `data_wrangle_and_clean.Rmd` document is set up to create the combined dataset necessary for the Outdoor Equity App. To access the ACS data we use the `tidycensus` package [@R-tidycensus] to access the necessary data via API, meaning data updates are not necessary outside of the `.Rmd` document. The RIDB data is accesses via direct download from the [Recreation.gov](https://ridb.recreation.gov/download) website. See the [How to Expand the Outdoor Equity App Section][How to Expand the Outdoor Equity App] on expanding the time periods included in the App.

### Server Hosting



### Shiny Code Directory



## How to Expand the Outdoor Equity App

### Temporal Expansions



### Spatial Expansions



### Statistical Analysis

